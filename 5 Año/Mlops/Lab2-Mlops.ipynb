{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5323015e",
   "metadata": {},
   "source": [
    "`GridSearchCV` es una herramienta poderosa proporcionada por la biblioteca Scikit-learn en Python, diseñada para automatizar el proceso de ajuste de hiperparámetros de un modelo. Esta herramienta permite a los usuarios especificar un conjunto de valores potenciales para los distintos hiperparámetros de un modelo y evaluar todas las combinaciones posibles para encontrar la configuración que produce los mejores resultados de acuerdo con una métrica de evaluación especificada.\n",
    "\n",
    "### Funcionamiento de GridSearchCV\n",
    "\n",
    "**1. Definición de la cuadrícula de parámetros:**\n",
    "   - Se define un \"grid\" de hiperparámetros, que es básicamente un diccionario donde las claves son los nombres de los hiperparámetros y los valores son las listas de valores que se desean explorar para cada hiperparámetro.\n",
    "\n",
    "**2. Configuración del modelo:**\n",
    "   - Se selecciona el modelo de machine learning que se desea ajustar.\n",
    "\n",
    "**3. Evaluación cruzada:**\n",
    "   - `GridSearchCV` implementa una técnica de validación cruzada para evaluar cada combinación de hiperparámetros. Esto significa que para cada conjunto de hiperparámetros, el modelo se entrena varias veces en diferentes subconjuntos del conjunto de datos de entrenamiento.\n",
    "\n",
    "**4. Selección del mejor modelo:**\n",
    "   - Después de probar todas las combinaciones posibles, `GridSearchCV` selecciona la combinación de hiperparámetros que resulta en el mejor rendimiento del modelo según una métrica específica (como precisión, recall, F1-score, etc.).\n",
    "\n",
    "### Beneficios de usar GridSearchCV\n",
    "\n",
    "- **Automatización y simplificación**: Automatiza un proceso que de otra manera sería tedioso y propenso a errores, simplificando la búsqueda de la mejor configuración de hiperparámetros.\n",
    "- **Robustez**: Al utilizar la validación cruzada, GridSearchCV asegura que el rendimiento del modelo es evaluado de manera más robusta y menos susceptible a las fluctuaciones del conjunto de datos de entrenamiento.\n",
    "- **Mejor rendimiento**: Al explorar sistemáticamente múltiples combinaciones, se incrementa la probabilidad de encontrar una configuración de hiperparámetros que resulte en un mejor rendimiento del modelo.\n",
    "\n",
    "### Ejemplo de uso de GridSearchCV\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aae9574f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'max_depth': 30, 'n_estimators': 200}\n",
      "Mejor puntuación: 0.9061887254901961\n"
     ]
    }
   ],
   "source": [
    "# Paso 1: Importar las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Paso 2: Cargar los datos\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "data = pd.read_csv(url, sep=';')\n",
    "\n",
    "# Paso 3: Preparar los datos\n",
    "X = data.drop('quality', axis=1)  # características\n",
    "y = data['quality'] > 6  # objetivo, convertido en problema binario\n",
    "\n",
    "# Paso 4: Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Paso 5: Escalar las características (opcional, dependiendo del modelo)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Paso 6: Configurar GridSearchCV\n",
    "param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [10, 20, 30]}\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
    "\n",
    "# Paso 7: Entrenar con GridSearchCV\n",
    "grid_search.fit(X_train_scaled, y_train)  # Asegúrate de usar X_train_scaled si aplicaste escalado\n",
    "\n",
    "# Paso 8: Imprimir los mejores parámetros y la mejor puntuación\n",
    "print(\"Mejores parámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor puntuación:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70def031",
   "metadata": {},
   "source": [
    "### Lo mismo para: \n",
    "\n",
    "# from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "387d8764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'learning_rate': 0.1, 'n_estimators': 50}\n",
      "Mejor puntuación: 0.8874234068627451\n"
     ]
    }
   ],
   "source": [
    "# Paso 1: Importar las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Paso 2: Cargar los datos\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "data = pd.read_csv(url, sep=';')\n",
    "\n",
    "# Paso 3: Preparar los datos\n",
    "X = data.drop('quality', axis=1)  # características\n",
    "y = data['quality'] > 6  # objetivo, convertido en problema binario\n",
    "\n",
    "# Paso 4: Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Paso 5: Escalar las características (opcional, dependiendo del modelo)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Paso 6: Configurar GridSearchCV\n",
    "param_grid = {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1.0]}\n",
    "grid_search = GridSearchCV(AdaBoostClassifier(), param_grid, cv=5)\n",
    "\n",
    "# Paso 7: Entrenar con GridSearchCV\n",
    "grid_search.fit(X_train_scaled, y_train)  # Asegúrate de usar X_train_scaled si aplicaste escalado\n",
    "\n",
    "# Paso 8: Imprimir los mejores parámetros y la mejor puntuación\n",
    "print(\"Mejores parámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor puntuación:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4fea00",
   "metadata": {},
   "source": [
    "La diferencia principal entre el código anterior radica en el modelo utilizado en el proceso de búsqueda de hiperparámetros.\n",
    "\n",
    "Aunque ambos son algoritmos de conjunto, funcionan de manera diferente. \n",
    "\n",
    "RandomForestClassifier crea un conjunto de árboles de decisión, mientras que AdaBoostClassifier crea un conjunto de clasificadores débiles (árboles de decisión débiles) que se ajustan secuencialmente, centrándose en los casos más difíciles en cada iteración."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1c49e1",
   "metadata": {},
   "source": [
    "Para la búsqueda de hiperparámetros con GridSearchCV en el modelo AdaBoostClassifier, puedes definir los valores que deseas probar para los siguientes parámetros:\n",
    "\n",
    "n_estimators: Este parámetro controla el número de clasificadores débiles utilizados en el conjunto. Un valor mayor de n_estimators generalmente conlleva a un mejor rendimiento, pero también aumenta el costo computacional.\n",
    "\n",
    "Ejemplo de valores: [50, 100, 200]\n",
    "\n",
    "learning_rate: Este parámetro controla la contribución de cada clasificador débil al modelo final. Valores más bajos hacen que cada clasificador tenga una contribución menor, lo que generalmente conduce a un modelo más robusto.\n",
    "\n",
    "Ejemplo de valores: [0.01, 0.1, 1.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f5a8f2",
   "metadata": {},
   "source": [
    "La validación cruzada (cross-validation en inglés) es una técnica utilizada para evaluar el rendimiento de un modelo de manera más robusta y precisa, especialmente cuando el conjunto de datos es limitado. En el contexto de GridSearchCV, se utiliza para evaluar diferentes combinaciones de hiperparámetros en un modelo a través de múltiples divisiones del conjunto de datos en conjuntos de entrenamiento y prueba."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
